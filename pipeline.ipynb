{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "def plot_waveform(waveform, sr, title=\"Waveform\"):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sr\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    for axis in axes:\n",
    "        axis.plot(time_axis, waveform[0], linewidth=1)\n",
    "        axis.grid(True)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\"):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_fbank(fbank, title=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Filter bank\")\n",
    "    axs.imshow(fbank, aspect=\"auto\")\n",
    "    axs.set_ylabel(\"frequency bin\")\n",
    "    axs.set_xlabel(\"mel bin\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "SAMPLE_SPEECH = \"sampledata/sample1.wav\"\n",
    "\n",
    "SPEECH_WAVEFORM, SAMPLE_RATE = torchaudio.load(SAMPLE_SPEECH)\n",
    "\n",
    "plot_waveform(SPEECH_WAVEFORM, SAMPLE_RATE, title=\"Original waveform\")\n",
    "Audio(SPEECH_WAVEFORM.numpy(), rate=SAMPLE_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(n_fft=1024, win_length=None, hop_length=512):\n",
    "    # Define transform\n",
    "    return T.Spectrogram(\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_length,\n",
    "        hop_length=hop_length,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0,\n",
    "    )\n",
    "\n",
    "spec = spectrogram()(SPEECH_WAVEFORM)\n",
    "plot_spectrogram(spec[0], title=\"torchaudio\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recover waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_spectrogram(n_fft=1024, win_length=None, hop_length=512):\n",
    "    return T.GriffinLim(\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_length,\n",
    "        hop_length=hop_length,\n",
    "    )\n",
    "\n",
    "reconstructed_waveform = recover_spectrogram()(spec)\n",
    "\n",
    "plot_waveform(reconstructed_waveform, SAMPLE_RATE, title=\"Reconstructed\")\n",
    "Audio(reconstructed_waveform, rate=SAMPLE_RATE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
